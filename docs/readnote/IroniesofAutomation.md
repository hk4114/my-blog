# 【译】《自动化的反讽》（Ironies of Automation）

[原文链接](https://ferd.ca/notes/paper-ironies-of-automation.html)

让人惊讶的是，我竟未曾分享过这篇来自Lisanne Bainbridge的经典基础性论文《自动化的反讽》的笔记。作者在其官网上发布了[修订版本](https://www.complexcognition.co.uk/2021/06/ironies-of-automation.html)，这距离原版发表已近40年，值得一览。该论文被引用超过1800次，拥有专属维基百科页面，是任何涉及自动化研究的必读文献。

---

## 核心论点

本文的核心论点是：无论自动化程度如何发展，系统本质上仍是人机系统。即使自动化范围不断扩大，人的因素始终至关重要。文中案例来自工业控制流程与飞行甲板自动化，但其洞见至今依然适用。作者通过列举一系列反讽现象，并探讨应对方法，来论证这一观点。

---

## 自动化流程的基本要求

整个过程围绕两个基础需求展开：

1. 需要人员监控自动化是否正常运行
2. 需要人员在异常时接管系统

这两项需求与我们使用自动化的初衷存在根本性矛盾。

---

## 认知与操作技能的衰退

首个矛盾源于认知与操作技能的衰退：两种技能长期不用都会退化。更高的专业技能意味着更高效顺畅的操作能力。当操作员长期仅执行监控任务时，其鲜少使用的接管技能可能退化至低于实际需要的水准。

特别值得注意的是：自动化系统越完善，操作员需要接管的情况就越罕见且复杂。这意味着自动化程度越高，反而需要操作员具备更高技能水平——因为处理的将是最棘手且缺少实操训练的突发状况。

---

## 认知行为与反馈机制

这一现象同样体现在认知领域：只有在快速频繁的反馈中，认知技能才能持续强化。当自动化系统刚部署时，操作员可能还保有通过人工操作磨练出的扎实技能。但经过一定时间后，新一代操作员无法获得同强度的实时反馈环境，最终可能导致他们处理事务的速度变慢、动作更刻意识别而非自动化反应。

---

## 警戒度与告警设计

监控罕见异常需要持续警戒，但人类只习惯关注常用数据，这迫使系统需要自动告警。但复杂系统随着所需响应速度提升，告警数量也需增加；而告警过多又会引发信息过载（我曾撰文讨论过告警设计原则）。

---

## 自动化的反讽定律

这引出一个重大反讽：人们为提升效率而自动化，却要求人类检查修正自动化错误：

> 如果决策规则可以完全形式化，计算机能比人类更快处理更多维度、执行更精确的判断。操作员根本无法实时核验计算机是否遵循规则，只能进行元层级监控（判断结果是否"可接受"）。但若当初采用自动化的原因就是人类直觉判断在此领域不可靠，那么"接受哪个决策"就成了伪命题——监控任务实质上是不可能完成的。

---

## 隐患遮蔽与系统性故障

类似地，旨在通过自修正功能辅助操作员的自动化系统，可能长期掩盖深层隐患。当自动化达到极限时，问题往往已发展到不可控阶段。

---

## 人机协调的运行节奏

作者由此推论：若以人类为最终防线，自动化系统应以适合人类的节奏运行：

> 若必须让操作员追踪计算机的决策细节，反讽地将导致：计算机必须采用操作员能理解的判定方式和速率——尽管这可能并非技术最优解。若违背此原则，当操作员质疑系统决策时，将无法回溯验证计算机的推演路径。

---

## 故障应对策略

针对故障处理，Bainbridge建议优先采用手动停机策略：停止、检查、理解、修复、重启。当然这在核电管控或飞行状态等场景难以实现。对于缓慢发展的故障，通过充分练习形成应急反射是可行方案；但对于爆发速度快于人力反应的故障，必须构建可靠的自动化响应机制。若无法实现或风险过高，作者直言不应建造此类系统。

---

## 操作员能力保持

为维持操作员技能，她建议定期手动执行关键步骤。若不可行，则采用模拟训练系统。但需要注意：要训练快速响应能力，模拟器必须具备高拟真度并支持动态情境。她补充道：

> 未知故障无法模拟，可预测但未实际经历的故障其系统行为也不明确...虽然无法教授系统未知特性，但可训练其在已知信息框架内解决问题。要求操作员仅凭规程应对陌生事件是荒谬的——这既无法穷尽可能性，又期待他们主动填补漏洞。更讽刺的是：先通过按章操作培训限制思维，又要求他们在实际中发挥主观能动性。

---

## 高自动化系统的培训投入

由此衍生第二个反讽：覆盖场景最广的高度自动化系统，恰恰需要最大规模的培训投资。

---

## 复杂系统中的人类介入

当考量因素超出单纯效率时，Bainbridge预测人类介入将不可或缺——尤其在公众无法接受纯自动化高风险系统的领域。这使她断言人机协作是必然选择，但实施路径充满挑战。例如计算机可提供操作建议列表，但如果信任计算机的决策能力，理应将可行的部分直接自动化，而非仅让人执行指令。

---

## 人因错误与系统设计

关于"纠正""人因错误"，她提出更优方案是设置执行效果的检查机制，而非严格控制特定操作步骤。这为操作者保留策略调整空间以适应具体情况。文中还讨论了电子显示屏与硬件监测仪的对比，以及操作模式情境敏感性带来的认知挑战（涉及技能、规则和知识的协调运用）。

---

## 总结

最终结论指向团队协作的重要性，并警示生产效率压力的潜在代价：

> 人类必须明确知晓计算机正在处理的任务及其方式，否则将重现人类团队职责不清时的经典问题。

> 无时间压力时，人类是出色的问题解决者。难点在于快速响应场景下效能骤降。本文既揭示了自动化未必能消除难点的讽刺现实，也展望了解决这些难题可能需要超越传统自动化的技术智慧。
