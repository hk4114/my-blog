# 【译】模型即产品（The Model is the Product）

[原文链接](https://vintagedata.org/blog/posts/model-is-the-product)

> 作者：Alexander Doria
>
> 翻译：kanelogger

过去数年间，关于人工智能下一阶段发展的猜想层出不穷。智能体（Agents）？推理系统（Reasoners）？还是彻底的多模态？

是时候给出结论了：模型即产品。

当前研发与市场发展的所有要素都在推动这一趋势。

- **通用模型扩展陷入停滞**。GPT-4.5的发布传递了明确信号：模型能力呈线性增长，而算力成本却在几何级攀升。即便结合过去两年的训练效率提升与基建优化，OpenAI仍无法以合理成本部署这个庞然大物。
- **特定任务的强化训练效果远超预期**。强化学习与推理能力的结合，使得模型突然掌握了任务执行能力。这既非传统机器学习，亦非基础模型，而是全新的第三形态。微型模型在数学领域突飞猛进，代码模型从单纯生成代码演进到自主管理整个代码库，Claude仅凭有限上下文就能玩转《精灵宝可梦》，皆是明证。
- **推理成本断崖式下跌**。DeepSeek的最新优化意味着现有GPU集群已能支持前沿模型为全球人口每人每天处理10k tokens。市场需求远未达到此量级，按量收费的商业模式难以为继，模型厂商必须向价值链上游迁移，去做更高附加值的事情。

这一趋势同样引发不安。投资者普遍押注应用层，但人工智能的下一阶段进化中，应用层或将率先被自动化重构。

## 下一代模型的形态

过去数周，我们见证了新一代模型即产品的两大典范：OpenAI的DeepResearch与Claude Sonnet 3.7。

针对DeepResearch的误读普遍存在。OpenAI并未在O3模型上简单封装功能，而是[训练了全新架构](https://cdn.openai.com/deep-research-system-card.pdf)。这个能自主执行搜索任务的研究型语言模型，无需外部调用或流程编排：

> 模型通过强化学习掌握了核心浏览能力（搜索、点击、滚动、文件解析）...以及如何通过推理整合海量网站信息来撰写综合性报告。

与常规LLM或聊天机器人不同，DeepResearch展现出独特的结构化报告生成能力。正如Hanchung Lee[指出](https://leechunglee.github.io/blogs/2025/02/26/deep-research/)，其他同类产品（包括Perplexity和Google版本）仍停留在传统模型微调层面：

> 这些系统既未公开任务优化方法，也缺乏量化评估...我们有理由推测其微调工作并不深入。

Anthropic则通过去年提出的[智能体定义](https://www.anthropic.com/research/building-effective-agents)阐明方向。与DeepSearch类似，真正的智能体需具备任务自主性："动态控制自身流程与工具使用，保持任务达成方式的自主决策权"。

当前多数"智能体"初创公司构建的实为工作流系统——通过预设代码路径编排LLM与工具。这类系统在垂直领域仍有价值，但对大厂研发人员而言，系统级进步必然源自模型架构重构。

Claude 3.7的发布提供了绝佳例证。这个针对复杂代码场景训练的模型，在软件工程基准测试中碾压了Devin等工作流系统。在我们实验室Pleias，RAG系统的自动化改造同样印证此理：传统RAG的脆弱工作流（路由、分块、重排、查询扩展等）正被两个互联模型取代——数据预处理模型与检索/生成模型。这需要全新的合成数据管道与强化学习奖励机制。

**核心逻辑在于复杂度转移**：通过训练预判各类操作与边缘案例，部署复杂度大幅降低。在此过程中，模型训练者创造并最终捕获了主要价值。正如Claude意图取代的llama index基础智能体系统所示：

![Llama Index Basic Agent](https://huggingface.co/datasets/Pclanglais/course-material/resolve/main/llama_index.png)

正被这样的架构取代：

![Claude Agent](https://huggingface.co/datasets/Pclanglais/course-material/resolve/main/claude.png)

## 训练者或被训练

必须重申：大厂并未隐藏战略意图。尽管存在信息壁垒，他们的路线图清晰可辨——整合功能、渗透应用层、捕获价值链顶端。Databricks生成式AI副总裁Naveen Rao的[论断](https://x.com/NaveenGRao/status/1886544584588619840)颇具代表性：

> 未来2-3年内，闭源模型厂商将停止API销售，仅开源模型保留接口...闭源厂商正在构建非标能力，需要优秀UI来交付价值。这不再是单纯模型，而是面向具体场景的应用套件。

当前市场充斥着认知滞后。模型厂商与应用封装器的蜜月期已告终结，演化路径呈现双向分化：

- Claude Code与DeepSearch是早期技术实验品。值得注意的是，DeepSearch未开放API，仅服务于高级订阅用户；Claude Code采用极简终端集成。有趣的是，Claude 3.7在自家环境运行流畅，而第三方IDE Cursor却适配困难，已导致高端用户流失。
- 头部封装器正转型混合训练公司。Cursor的自动补全模型、WindSurf的廉价代码模型Codium、Perplexity自研的DeepSeek搜索变体，皆是明证。
- 中小型封装器或将依赖通用推理服务商，并更聚焦UI优化——这个仍被严重低估的领域，特别是在通用模型开始整合RAG等部署任务的趋势下。

**本质困境在于：成为训练者，或沦为训练数据**。当前封装器不仅为大厂提供免费市场调研，更危险的是，由于所有输出最终经由模型生成，它们实质上在免费设计数据。

## 未被定价的强化学习

当前投资市场的集体误判令人担忧。风投机构的预设存在系统性偏差：

- 价值完全存在于独立于模型层的应用层
- 模型厂商将持续降价销售算力
- 闭源封装器可满足所有需求（包括监管敏感领域）
- 任何形式的模型训练（不仅是预训练）都是资源浪费

这越来越像场冒险赌博，暴露出市场对技术进展（特别是强化学习）的定价失效。在衰退预期笼罩的西方经济体背景下，模型训练本应是绝佳的风险对冲标的，但现实是：

- 除大厂外，训练生态圈规模极小。Prime Intellect、Moondream、Arcee等公司，加上HuggingFace预训练团队（实际规模有限），构成了主要开源基础设施力量。
- 欧洲至少7-8个LLM项目将整合Common Corpus语料库，其他则依赖Nous等机构的指令微调工具。

OpenAI最近的[公开表态](https://x.com/khoomeik/status/1892743475843813680)暗示行业焦虑。Sam Altman传递的信号清晰：未来大厂的核心合作伙伴将不是API客户，而是参与早期训练阶段的承包商。

当模型即产品，单打独斗难以为继。搜索与代码是唾手可得的低垂果实，而更多高价值场景（如统治实体经济的规则系统）尚待开发。专注特定领域的小型团队可能率先突破，最终被收编入大厂体系。

未提及DeepSeek与中国实验室，皆因其已迈入新阶段。正如梁文峰在[访谈](https://www.lesswrong.com/posts/kANyEjDDFWkhSKbcK/two-interviews-with-the-founder-of-deepseek)中所述：

> 当前的AI发展，是技术创新的爆发期而非应用爆发期...完整产业链形成后，我们无需亲自开发应用。当然必要时亦可下场，但科研创新始终是首要任务。

在这个新时代，固守应用层如同"用旧时代将领打下一场战争"。可悲的是，西方许多人尚未意识到：旧战争早已落幕。

以上，就是目前AI发展的大势所趋：模型本身已经成为产品本身，谁掌握模型训练，谁就掌握未来。

