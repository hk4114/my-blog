---
title: Mine Weekly 第 63 期
description:
outline: [2, 3]
hidden: true
date: 2025-03-02
recommend: -83
---

## 🚀 科技动态

> 最新的科技进展和市场动态，包括新闻、行业动态、趋势分析

### Microsoft’s agi plan & quantum breakthrough.
> https://weibo.com/1233486457/5136451919938638
>
> youtube 原视频


### Perplexity 的联合创始人：做好AI搜索需要二十年，谷歌办不成是因为会动广告的奶酪
> https://weibo.com/1233486457/PfOxEm8hi

在达沃斯论坛期间， Perplexity 的联合创始人兼 CEO Aravind Srinivas和CNBC的一次关于DeepSeek的访谈，为Aravind Srinivas赢得了无数好感。关于DeepSeek为什么能成功 ，有两句国外企业家的证言，一句就是他那句出圈的“需求是创新之母”；另一句是前英特尔CEO基辛格的“工程的本质在于约束”。


### 微软研究员访谈：让我们将20年的AI学习浓缩到90分钟 We condense 20 years of AI learning into 90 minutes
> https://weibo.com/1233486457/Pg7bE0iF4

油管博主Let's Dive Right In采访了微软研究院的高级首席研究经理Akshay Krishnamurthy，对从GPT-2谈到DeepSeek，从AI算力谈到电力消耗，还真是涵盖了十几年来主要的AI议题。

## 💻 技术文章

> 各种技术的应用和实践方法，包括各种技术文章、教程、实践案例等内容

### 从零开始实现一个稀疏专家混合语言模型（MoE模型）
> https://huggingface.co/blog/AviSoori1x/makemoe-from-scratch

hugging face 的一篇博客。本项目灵感来源于 Andrej Karpathy 的项目“makemore”。文章通过逐步解析代码，展示了如何构建自注意力机制、专家模块、Top-k 门控机制以及稀疏 MoE 模块，并将其整合为一个完整的语言模型。阅读本文，可以深入了解稀疏 MoE 架构的实现细节、训练过程以及如何通过代码实现高效的模型训练和推理。


## 🔧 工具资源

> 如何使用这些工具提高工作效率，包括各种技术工具、软件、插件等方面的内容，各种技术资源、免费课程、学习资料

### 软件工程师的软技能指北
> https://ramsayleung.github.io/zh/post/2023/%E6%80%BB%E8%A7%88%E7%AF%87/?continueFlag=c9145e140c50db21984956e9f4f39f7f

这是作者结合《软技能，代码之外的生存指南》和自身经验写的一系列总结.目录如图（其中第五篇面试篇还没写。）
“所谓的软技能，是区别与使用C++或Java 编写业务逻辑和单元测试代码，使用Docker 部署等「硬技能」，而是注重职场，心态，身体与理财等各方面提升的「软技能」。

软件工程师大部分时间都在与人打交道：

拿到需求时，需要分析需求的可行性，与产品经理扯皮，理清模糊之处
撰写设计文档，和组员及老板介绍方案，比较方案优劣，选择最优解
与上下游团队扯皮，求下游团队帮忙干活，给上游团队表演太极
和老板画饼，只要再给我些时间，定然能做得成绩斐然。
哪项不是与人打交道呢？项项都是我缺乏的技能阿，我就只会接活，干活，然后再接再干。

老黄牛听到我这境况，估计都得叫我一声兄弟；流水线见我这际遇，也会直呼一声「内行」

所以「软技能」真的是不可或缺。
”

### 如何从零开始实现一个稀疏 MoE（混合专家）模型
> https://huggingface.co/blog/AviSoori1x/makemoe-from-scratchGitHub%EF%BC%9Agithub.com/AviSoori1x/makeMoE

从介绍 MoE 模型的基本组成，包括自注意力机制、MoE 块中的专家网络、Top-k 路由和噪声 Top-k 路由等。

再到逐步演示每个组件的代码实现，包括自注意力头、多头自注意力、专家模块、Top-k 路由器、噪声 Top-k 路由器以及完整的 MoE 变换器块。

文章地址：huggingface.co/blog/AviSoori1x/makemoe-from-scratch
GitHub：github.com/AviSoori1x/makeMoE

此外，作者还提供了模型的初始化方法、训练循环和生成文本的示例。

并强调了 MoE 模型在训练稳定性和效率方面的内容，如优化 MoE 模块的效率、尝试不同的神经网络初始化策略、从字符级到子词分词等。

### AI系统
> https://chenzomi12.github.io/index.html

### maxiee 的 AI 全栈项目

> https://github.com/maxiee/RaySystem

AI 全栈项目，是一个用于打造超级个体的工作流，涵盖 RaySystem Server（Python）、RaySystem Client（Flutter）、以及精挑细选的优秀软件，组成一个完整生态。

本开源项目主要是跟大家一起探讨和学习人工智能、深度学习的系统设计，而整个系统是围绕着在 NVIDIA、ASCEND 等芯片厂商构建算力层面，所用到的、积累、梳理得到 AI 系统全栈的内容。希望跟所有关注 AI 开源项目的好朋友一起探讨研究，共同促进学习讨论。

课程主要包括以下六大模块：

第一部分，AI 基础知识和 AI 系统的全栈概述的 AI 系统概述，以及深度学习系统的系统性设计和方法论，主要是整体了解 AI 训练和推理全栈的体系结构内容。

第二部分，硬核篇介绍 AI 芯片概况，这里就很硬核了，从芯片基础到 AI 芯片的范围都会涉及，芯片设计需要考虑上面 AI 框架的前端、后端编译，而不是停留在天天喊着吊打英伟达，被现实打趴。

第三部分，进阶篇介绍 AI 编译器原理，将站在系统设计的角度，思考在设计现代机器学习系统中需要考虑的编译器问题，特别是中间表达乃至后端优化。

第四部分，实际应用推理系统与引擎，讲了太多原理身体太虚容易消化不良，还是得回归到业务本质，让行业、企业能够真正应用起来，而推理系统涉及一些核心算法和注意的事情也分享下。

第五部分，介绍 AI 框架核心技术，首先介绍任何一个 AI 框架都离不开的自动微分，通过自动微分功能后就会产生表示神经网络的图和算子，然后介绍 AI 框架前端的优化，还有最近很火的大模型分布式训练在 AI 框架中的关键技术。

第六部分（这部分还没写），汇总篇介绍大模型与 AI 系统，大模型是基于 AI 集群的全栈软硬件性能优化，通过最小的每一块 AI 芯片组成的 AI 集群，编译器使能到上层的 AI 框架，训练过程需要分布式并行、集群通信等算法支持，而且在大模型领域最近持续演进如智能体等新技术。

### 麻省理工的一门新的公开课：《如何用 AI（几乎）做任何事》

mit-mi.github.io/how2ai-course/spring2025/
要充分发挥 AI 的作用，AI 系统需要扎根于现实世界的数据模态，从仅限语言的系统扩展到视觉、音频、传感器、医疗数据、音乐、艺术、嗅觉、味觉等。本课程将介绍 AI 的基本原理（重点关注现代深度学习和基础模型），以及如何将 AI 应用于各种新型的现实世界数据模态。此外，还将介绍多模态 AI 的原理，它能同时处理多种模态，例如将语言与多媒体、音乐与艺术、感知与执行等结合起来。
目前课程还未结束，课程主页右上角 Schedule 链接那里可以下载部分课件和参考资料

### 底层程序员的学习路线图

github.com/gurugio/lowlevelprogramming-university
虽然现在都在谈大模型，谈人工智能，但理解计算机底层运作机制也还是很重要的。这份路线图提供了从理论学习到实践操作的详细路线图，涵盖计算机架构、操作系统、编程语言（如汇编、C 语言和 Rust）以及 Linux 内核开发等内容。里面有中文版但是好久没更新了，可以直接看英文版。

### AI Agents for Beginners 微软出了一门给初学者学习的 AI 智能体课程

> https://github.com/microsoft/ai-agents-for-beginners

共 10 节课程，涵盖构建 AI 智能体的所有基础知识，旨在教授我们从零开始构建一个 AI 智能体。课程内容已做了中文翻译，学习起来更加轻松，同时提供每节课所使用的示例代码，方便我们运行。


## 😛 我在看
