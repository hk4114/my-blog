---
title: Mine Weekly 第 62 期
description:
outline: [2, 3]
hidden: true
date: 2025-02-23
recommend: -83
---

## 🚀 科技动态

> 最新的科技进展和市场动态，包括新闻、行业动态、趋势分析

### 马斯克 20 万块 GPU 炼出 Grok-3

> https://mp.weixin.qq.com/s/YDjin48P-qsxPv48mpCbtg

马斯克旗下 xAI 团队发布全新 AI 模型 Grok-3，基于 20 万块 GPU 训练，刷新数学（AIME 2024）、科学（GPQA）和编码（LCB）领域 SOTA 表现，Elo 评分突破 1400 成为全球最强模型。其创新功能包括 Think 模式（展示思维链解决航天轨道计算等复杂任务）、Big Brain 模式（增强算力生成混合游戏代码）及智能体 DeepSearch（深度联网搜索并透明化推理过程），击败 DeepSeek-R1、GPT-4o 等竞品。模型已向订阅用户开放，计划数月内全面开源，并优化数据中心能耗。业界评价其推理能力媲美顶级商用模型，标志着 xAI 在 19 个月内实现从零到技术巅峰的突破。

## 💻 技术文章

> 各种技术的应用和实践方法，包括各种技术文章、教程、实践案例等内容

### 低代码平台的末路-AI 编程王者归来

> https://mp.weixin.qq.com/s/NKZ6aWih3ZV8ZrMukP0BMg

作者认为，随着 AI 编程能力的飞速发展，低代码平台将逐渐被取代。尽管低代码平台通过集成 AI 功能实现了“一句话生成应用”的便捷性，但其本质仍受限于模板化和规则约束，而 AI 编程凭借灵活性、通用性及智能化优势，将成为未来开发的主流方式。

低代码平台如同"手机加速器"，在早期提升效率，但随着底层技术（AI）的成熟，其附加价值消失，甚至成为负担（如性能损耗、维护成本）。

核心逻辑对比

低代码平台

- **实现方式**  
  通过可视化界面、预设模板和脚本语言，自动化完成对象建模、数据库设计、流程配置等。
- **优势**
  - 降低开发门槛，非专业开发者可快速搭建简单应用
- **局限性**
  - 依赖模板，定制化能力不足，复杂需求下效率骤降
  - 生成代码非通用，存在平台绑定风险，可维护性差
  - 脚本语言解析消耗性能，扩展性受限

AI 编程

- **实现方式**  
  基于自然语言处理（NLP）和机器学习（ML），解析用户需求并直接生成优化代码（如 GitHub Copilot）。
- **优势**
  - 需求驱动，无需模板，适应复杂、多样化场景
  - 生成通用代码，避免平台绑定，支持全栈开发
  - 提供代码补全、错误修复、安全检测等智能化功能

关键维度对比

| 维度         | 低代码平台                         | AI 编程                                 |
| ------------ | ---------------------------------- | --------------------------------------- |
| **效率**     | 简单应用开发快，复杂需求效率低     | 自动生成代码，智能补全，整体效率更高    |
| **扩展性**   | 受限于模板，难以应对复杂需求       | 灵活生成代码，适应多样化业务场景        |
| **技能要求** | 非专业开发者易上手                 | 需一定编程基础以优化 AI 输出            |
| **成本**     | 初期成本低，但长期维护成本可能增加 | 需硬件/软件投入，长期效率提升降低总成本 |
| **大型项目** | 难以满足复杂需求                   | 生成高质量代码，支持大型项目协作        |
| **可维护性** | 平台绑定，代码维护困难             | 代码通用、可读性强，便于修改扩展        |
| **安全性**   | 依赖平台设计，存在潜在风险         | 通过安全检测生成更安全的代码            |

核心替代原因

1. **灵活性**：直接生成代码，无模板限制
2. **性能优势**：避免脚本解析开销，代码更高效
3. **开放性**：生成通用代码，避免平台锁定

未来展望

- **低代码剩余价值**：仅适用于零代码场景（非技术用户快速搭建简单应用）
- **AI 主导地位**：在复杂项目、专业开发中成为主流，推动智能化转型

结论与建议

- 建议开发团队尽早转向 AI 编程实践，尤其是大型项目
- 充分利用 AI 的灵活性、高效性和可维护性优势
- 低代码平台可能继续服务非技术用户，但在专业开发领域将逐渐被取代

### 推理类模型的最佳实践

> https://platform.openai.com/docs/guides/reasoning-best-practices

OpenAI 官方博客发布，指导大家如何更好的使用 o1、o3 这类推理模型，当然也可以应用在 deepseek r1 上。

什么时候使用推理模型？

1. 处理模糊任务
2. 处理大量非结构化信息
3. 在大型数据集中寻找关系和细微差别
4. 多步骤
   怎么有效的用推理模型？
5. 保持提示简单直接
6. 避免思维链提示
7. 使用分隔符以提高清晰度：使用分隔符（如 Markdown、XML 标签和章节标题）来清楚地指示输入的不同部分，这有助于模型正确地解释各个部分。
8. 首先尝试零样本，如果需要再尝试少样本：推理模型通常不需要少样本示例就能产生好的结果，所以首先尝试编写没有示例的提示。 如果你对期望的输出有更复杂的要求，在提示中包含一些输入和期望输出的示例可能会有所帮助。但要确保示例与你的提示指令非常一致，因为两者之间的差异可能会导致不良结果。
9. 提供具体的指导方针： 如果你想明确地限制模型的响应（例如“提出一个预算低于 500 美元的解决方案”），请在提示中明确地列出这些约束条件。
10. 非常明确地说明你的最终目标： 在你的指令中，尝试为成功的响应提供非常具体的参数，并鼓励模型持续推理和迭代，直到符合你的成功标准。

### 如何更好的为 DeepSeek R1 或 OpenAI o1 这样的推理模型写提示词？

> https://techcommunity.microsoft.com/blog/azure-ai-services-blog/prompt-engineering-for-openai%E2%80%99s-o1-and-o3-mini-reasoning-models/4374010

1. 保证提示清晰且具体
   明确说明你想让模型完成什么。避免不相关的信息。如果问题复杂，可直接简要陈述，不要同时抛出多个话题或做过多背景描述。

2. 必要的上下文要提供，不相关的要省略
   包含模型所需的领域信息或数据（如案例、事实），因为模型未必具备最新或小众知识；但别堆砌与任务无关的材料或一堆示例，以免干扰。

3. 尽量零示例或极少示例
   优先采用零示例模式。只有当模型理解有误或者格式不对时，才加入简短的示例作为演示。O1/O3 本身不需要像旧版 GPT 那样大量示例来引导。

4. 使用 System/Developer 指令定位角色与风格
   比如「你是一位法律分析师」，或「请做一名数学老师给学生讲解」，从而设置合适的专业度和语气；再如「请用条列式列出答案」，指定输出结构。

5. 通过指令控制回答长度与详细程度
   若要简短回答，就写「限一段话内给出结论」；若要详细分析，就写「请详述你的推理过程」。O1 默认会倾向详尽，但你可以覆盖该默认。

6. 在 O3-mini 上使用“推理努力程度”参数
   （若 API 允许）根据任务需求设置低/中/高，以在速度与准确性之间做平衡。

7. 避免重复的“逐步思考”指示
   不必告诉 O1/O3「让我们一步步思考」，因为它们已在内部做链式推理；这类指令对 GPT-4o 更有效。只有当你想要输出“所有中间步骤”时才额外声明。

8. 测试和迭代
   如果初始回答不理想，可以改变提示表述或更精确地说明需求。虽然 O1/O3 通常一次就能给出高质量解答，但微调提示仍能进一步提升可读性或输出形式。

9. 对重要结论做验证
   对于需要高可靠度的回答，可进行追问或多次查询，并对比不同答案或让模型自检，以增强对结果的信心。即便是 O1 也有可能出错，务必审慎使用。

### 如何构建靠谱的 AI agent？

> https://www.anthropic.com/research/building-effective-agents

这是一篇来自于 Anthropic Claude 团队的座谈交流。他们围绕 agents 的定义、实践经验与未来展望展开了一个深入对话。

文章从理论到实践全面阐述了 AI agent 的开发要点：

1. 首先明确区分了 agent 和工作流的本质区别，agent 具有自主决策能力而非简单的固定流程；
2. 在代码实现层面，详细对比了工作流的线性特征和 agent 的灵活性；同时强调了开发者需要深入理解模型视角，在设计时保持同理心。
3. 在工具设计方面，文章指出了开发者常见的忽视工具接口友好性的误区。
   对于 agent 的应用前景，文章认为目前消费级 agent 被过度炒作，存在偏好表达复杂和风险控制等挑战，而企业级应用则更具潜力，特别适合自动化重复性任务。
   最后，专家们建议开发者建立完善的度量体系，并着眼于开发能随模型进步而持续改进的产品。

我印象比较深刻的有三句话：

1. Agents 不是工作流，而是管理工作流的自动化流程；
2. 对 Agents 工作要有同理心，人要站在机器的视角考虑流程是否奏效；
3. 最后一句，是奥特曼也说过很多次的，构建的工具要考虑模型演进，如果你的工具在模型演进之后失去意义了，那么即是坏选择，如果模型越好，你的工具越好，就是好选择。

## 🔧 工具资源

> 如何使用这些工具提高工作效率，包括各种技术工具、软件、插件等方面的内容，各种技术资源、免费课程、学习资料

### DeeSearcher 开源版 Deep Research

> https://github.com/zilliztech/deep-searcher

结合了大模型和向量数据库，为个人/企业知识管理、智能问答、信息搜索等场景提供高度准确的答案和全面分析。

支持本地文件导入，以及网络数据爬取等文档加载，支持 DeepSeek、OpenAI 等大模型。

### LangBot

> http://github.com/RockChinQ/LangBot

可扩展的通信机器人平台，提供了丰富生态、支持扩展、多模态的能力，用于构建大模型的即时通信机器人，支持接入 QQ、微信、飞书等平台。

同时支持多种主流大模型，如 DeepSeek、ChatGPT、Claude、Gemini、Ollama 等。

除此之外，还支持访问控制、限速、敏感词过滤等功能，支持多种部署方式，而且配置简单。

### Llama Tutor

> https://github.com/Nutlope/llamatutor

一款开源免费的 AI 个人导师工具。

集成 Llama 3.1 和 Serper 为工具提供强大的推理以及搜索能力，以达到高质量辅助教学。

输入任何想要了解的知识，以及选择能接受的教育水平，覆盖了小学到大学，即可为你生成个性化导师，解答一切疑难杂题。

### Company Researcher

> https://github.com/exa-labs/company-researcher

快速了解任何(外国)公司的开源 AI 工具：Company Researcher。

只需输入公司的网站链接，即可帮我们从互联网上全面收集关于该公司的信息，包括组织架构、产品、融资情况以及官方媒体账号等等信息。

抓取的数据主要来自各大平台开放的 API，如 Linkedin、X（Twitter）、Yogithub.com/exa-labs/company-researcheruTube、GitHub、Reddit 等。

最终汇总罗列一个详细面板给我们快速了解该家公司，不过从数据来看，主要面向国外公司。

### AudioNotes

> https://github.com/harry0703/AudioNotes

快速将音视频转结构化笔记的开源工具：。

基于 FunASR 和 Qwen2 构建，可快速提取音视频内容，并利用大模型能力整理成一份结构化的 Markdown 笔记，方便快速阅读。

工具支持搭配 Ollama 使用本地模型，并提供了 Docker 快速部署方式。

### Scira 开源 AI 搜索引擎

> https://github.com/zaidmukaddam/scira

集成 DeepSeek、Claude、Grok 等模型以及各种 API，实现了实时天气查询、代码片段运行、地图导航、学术搜索、视频搜索、X 帖子搜索等等功能。同时，提供简洁好用的可视化界面，并能为我们清晰展示相关搜索到的内容。可以通过 Vercel 快速部署使用。
