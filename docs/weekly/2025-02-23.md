---
title: Mine Weekly 第 62 期
description:
outline: [2, 3]
hidden: true
date: 2025-02-23
recommend: -83
---

## 🚀 科技动态

> 最新的科技进展和市场动态，包括新闻、行业动态、趋势分析

### Grok 3 是否意味着大力出奇迹的大模型法则仍然成立？

> https://weibo.com/1064649941/PeT6Asavy

摘要

1. **预训练阶段 Scaling Law 依然有效但性价比低**：数据不足时只能通过增大模型规模提升效果，但成本过高；
2. **技术路线选择依赖性价比排序**：Test Time 扩展（如思维链推理）> RL 扩展（如强化学习）> 预训练扩展；
3. **Grok 3 的策略逻辑**：通过推大基座模型规模，可能为后续 RL 阶段效果提升奠定基础；
4. **模型能力的循环进化**：当 Test Time 和 RL 扩展遇瓶颈时，可回归预训练扩展提升天花板，形成持续迭代。

核心观点

- 🔄 **Scaling Law 的阶段性特征**：
  - 预训练阶段扩展（数据/模型规模）仍是最后手段，但成本效益最低；
  - RL 和 Test Time 扩展是目前性价比更高的技术路线。
- 💡 **Grok 3 的潜在逻辑**：
  - 基座模型规模增大可能提升后续 RL 阶段效果的天花板；
  - 模型能力进化存在「预训练 →RL→Test Time→ 预训练」的循环依赖。
- ⚖️ **实践权衡**：
  - 卡多加速实验迭代，但预训练阶段过度堆算力可能得不偿失；
  - 开源大模型部署困难（如 Deepseek R1）反映基座规模与应用成本的矛盾。
- 🌐 **行业趋势**：
  - 蒸馏深度思考数据（如 Deepseek V3 的「左脚踩右脚」模式）成为提升基座能力的低成本方案；
  - 多模态数据对模型智商提升作用有限，文本数据规模或已接近上限。

### 微软的量子处理器有多厉害？

> https://weibo.com/1233486457/Pfd0dBPKe

微软最新发布的 Majorana 量子处理器基于拓扑量子比特技术，利用 Majorana 粒子"自身即反粒子"的独特量子特性，通过半导体与超导体复合新材料实现了量子态的拓扑保护，将量子比特稳定性提升至传统方案的百万倍级别。该处理器当前搭载 8 个量子比特，其模块化架构设计支持向百万级规模扩展，在药物研发、材料科学和密码学领域具备颠覆性应用潜力，已获得 DARPA 权威认证。尽管面临从实验室到量产的技术跨越、产业生态构建及多技术路线竞争等挑战，这项突破标志着量子计算从理论探索迈入工程化新阶段，或将成为继人工智能之后的下一个科技革命引擎，其最终产业化进程预计需要更长时间验证。

### 模型分类器

> 原文微博：https://weibo.com/1871474290/PfmSOCL4v?pagetype=detail

简而言之，先进行意图识别，然后进行任务派解，决定任务是由哪款模型起作用。

Berkeley 研发出一款 7B 的模型，该模型虽**不具备直接解答问题**的能力，但通过 150 万组对话质量评估数据训练，能够精准识别问题类型并调度最优解决方案。其创新之处在于整合了包括 GPT、Gemini、DeepSeek 等主流模型，让它知道什么问题应该找哪个模型回答，在 ELO 智能评估体系中取得 1400 分的优异表现。

Grok-3 模型宣称通过 20 万张计算卡也是 1400，而伯克利方案仅借助轻量级分类器与现有 API 接口便达成相同效果。这种技术路径可类比混合专家系统（MOE），其创新点在于延续了传统业务场景中基于任务类型的路由机制，而非当前主流大语言模型采用的 token 级分配策略。

值得关注的是，即将发布的 GPT-4.5/5 和 Claude 4 可能采用的系统融合方案，本质上遵循相似的技术逻辑。这种通过智能调度整合异构系统的架构模式，或将成为下一代人工智能系统的重要演进方向。

延伸：[General Reasoning](https://gr.inc/) 用于构建大型推理模型的新开源资源库。目前有 150 万个问题，27 万个思维链追踪（也就是各家的推理类大模型是如何回答这些问题的）。同时，还可以查到大模型回答这些问题准确性的排名，以及每个大模型擅长回答哪一类的问题和不擅长回答哪一类的问题。可以用这个数据来做一个「模型分类器」。

## 💻 技术文章

> 各种技术的应用和实践方法，包括各种技术文章、教程、实践案例等内容

### 时间码的身份验证

> https://www.schneier.com/blog/archives/2025/02/pairwise-authentication-of-humans.html

很多应用采用一次性时间码（TOTP），按照当前时间和用户生成一串数字，来验证用户身份。

一个程序员想到，完全可以用这种方法，验证是否见到了本人。

举例来说，A 和 B 从未见过，如何在见面时，确认来的是本人？

他们可以访问这个网址，输入双方的名称，系统分别为他们生成一个二维码。

他们将自己的二维码，保存到手机的验证器，以便生成时间码。见面时，如果双方的时间码一致，就表明来的是本人。

### 从第一性原理出发来介绍 AI Agent

> https://goyalpramod.github.io/blogs/AI_agents_from_first_principles/

文章详细介绍了 AI 代理的核心组件，包括提示（Prompts）、模型（Models）、工具（Tools）、记忆（Memory）以及检索增强生成（Retrieval Augmented Generation, RAG）等技术，并提供了具体的实现方法和代码示例。文章强调了在构建 AI 代理时应遵循的最佳实践，如最小化 LLM 调用、逐步迭代和优化系统性能。通过阅读本文，读者可以深入了解 AI 代理的构建过程，掌握如何使用 Python 和核心库实现复杂的 AI 代理系统，同时避免常见的开发陷阱。

### 低代码平台的末路-AI 编程王者归来

> https://mp.weixin.qq.com/s/NKZ6aWih3ZV8ZrMukP0BMg

作者认为，随着 AI 编程能力的飞速发展，低代码平台将逐渐被取代。尽管低代码平台通过集成 AI 功能实现了“一句话生成应用”的便捷性，但其本质仍受限于模板化和规则约束，而 AI 编程凭借灵活性、通用性及智能化优势，将成为未来开发的主流方式。

低代码平台如同"手机加速器"，在早期提升效率，但随着底层技术（AI）的成熟，其附加价值消失，甚至成为负担（如性能损耗、维护成本）。

核心逻辑对比

**低代码平台**

- **实现方式**  
  通过可视化界面、预设模板和脚本语言，自动化完成对象建模、数据库设计、流程配置等。
- **优势**
  - 降低开发门槛，非专业开发者可快速搭建简单应用
- **局限性**
  - 依赖模板，定制化能力不足，复杂需求下效率骤降
  - 生成代码非通用，存在平台绑定风险，可维护性差
  - 脚本语言解析消耗性能，扩展性受限

**AI 编程**

- **实现方式**  
  基于自然语言处理（NLP）和机器学习（ML），解析用户需求并直接生成优化代码（如 GitHub Copilot）。
- **优势**
  - 需求驱动，无需模板，适应复杂、多样化场景
  - 生成通用代码，避免平台绑定，支持全栈开发
  - 提供代码补全、错误修复、安全检测等智能化功能

关键维度对比

| 维度         | 低代码平台                         | AI 编程                                 |
| ------------ | ---------------------------------- | --------------------------------------- |
| **效率**     | 简单应用开发快，复杂需求效率低     | 自动生成代码，智能补全，整体效率更高    |
| **扩展性**   | 受限于模板，难以应对复杂需求       | 灵活生成代码，适应多样化业务场景        |
| **技能要求** | 非专业开发者易上手                 | 需一定编程基础以优化 AI 输出            |
| **成本**     | 初期成本低，但长期维护成本可能增加 | 需硬件/软件投入，长期效率提升降低总成本 |
| **大型项目** | 难以满足复杂需求                   | 生成高质量代码，支持大型项目协作        |
| **可维护性** | 平台绑定，代码维护困难             | 代码通用、可读性强，便于修改扩展        |
| **安全性**   | 依赖平台设计，存在潜在风险         | 通过安全检测生成更安全的代码            |

核心替代原因

1. **灵活性**：直接生成代码，无模板限制
2. **性能优势**：避免脚本解析开销，代码更高效
3. **开放性**：生成通用代码，避免平台锁定

未来展望

- **低代码剩余价值**：仅适用于零代码场景（非技术用户快速搭建简单应用）
- **AI 主导地位**：在复杂项目、专业开发中成为主流，推动智能化转型

结论与建议

- 建议开发团队尽早转向 AI 编程实践，尤其是大型项目
- 充分利用 AI 的灵活性、高效性和可维护性优势
- 低代码平台可能继续服务非技术用户，但在专业开发领域将逐渐被取代

### 如何用好推理型 AI？这份提示词设计指南请收好

> https://mp.weixin.qq.com/s/0KEpU2uidBSgsw07WGJZFg

结合 [OpenAI](https://platform.openai.com/docs/guides/reasoning-best-practices) 和 [微软](https://techcommunity.microsoft.com/blog/azure-ai-services-blog/prompt-engineering-for-openai%E2%80%99s-o1-and-o3-mini-reasoning-models/4374010) 的官方博客，整理出的提示词设计指南。

指导大家如何更好的使用推理模型。列举了适合使用 AI 推理的场景，分享设计推理友好型提示词的方法，指出新手常见误区及高手做法，并通过实战案例展示应用，最后以检查清单和总结四条 tip 强调关键要点，旨在助力更好利用 AI 进行深度思考。

### 如何构建靠谱的 AI agent？

> https://www.anthropic.com/research/building-effective-agents

这是一篇来自于 Anthropic Claude 团队的座谈交流。他们围绕 agents 的定义、实践经验与未来展望展开了一个深入对话。

文章从理论到实践全面阐述了 AI agent 的开发要点：

1. 首先明确区分了 agent 和工作流的本质区别，agent 具有自主决策能力而非简单的固定流程；
2. 在代码实现层面，详细对比了工作流的线性特征和 agent 的灵活性；同时强调了开发者需要深入理解模型视角，在设计时保持同理心。
3. 在工具设计方面，文章指出了开发者常见的忽视工具接口友好性的误区。
   对于 agent 的应用前景，文章认为目前消费级 agent 被过度炒作，存在偏好表达复杂和风险控制等挑战，而企业级应用则更具潜力，特别适合自动化重复性任务。
   最后，专家们建议开发者建立完善的度量体系，并着眼于开发能随模型进步而持续改进的产品。

我印象比较深刻的有三句话：

1. Agents 不是工作流，而是管理工作流的自动化流程；
2. 对 Agents 工作要有同理心，人要站在机器的视角考虑流程是否奏效；
3. 最后一句，是奥特曼也说过很多次的，构建的工具要考虑模型演进，如果你的工具在模型演进之后失去意义了，那么即是坏选择，如果模型越好，你的工具越好，就是好选择。

## 🔧 工具资源

> 如何使用这些工具提高工作效率，包括各种技术工具、软件、插件等方面的内容，各种技术资源、免费课程、学习资料

### aman.ai 专注于 AI 知识分享

> https://aman.ai/

每一篇都是维护者 Aman Chadha（AWS 的工程师）写的长文，很多图表和对比数据，尝试为你讲清楚这个概念。比如介绍 deepseek r1 的文章，直接整了 1 万多个单词，从 MoE、MLA、MTP 到强化学习，再到 deepseek 各个不同版本的对比之类都有。

### DeeSearcher 开源版 Deep Research

> https://github.com/zilliztech/deep-searcher

结合了大模型和向量数据库，为个人/企业知识管理、智能问答、信息搜索等场景提供高度准确的答案和全面分析。

支持本地文件导入，以及网络数据爬取等文档加载，支持 DeepSeek、OpenAI 等大模型。

### LangBot

> http://github.com/RockChinQ/LangBot

可扩展的通信机器人平台，提供了丰富生态、支持扩展、多模态的能力，用于构建大模型的即时通信机器人，支持接入 QQ、微信、飞书等平台。

同时支持多种主流大模型，如 DeepSeek、ChatGPT、Claude、Gemini、Ollama 等。

除此之外，还支持访问控制、限速、敏感词过滤等功能，支持多种部署方式，而且配置简单。

### Llama Tutor

> https://github.com/Nutlope/llamatutor

一款开源免费的 AI 个人导师工具。

集成 Llama 3.1 和 Serper 为工具提供强大的推理以及搜索能力，以达到高质量辅助教学。

输入任何想要了解的知识，以及选择能接受的教育水平，覆盖了小学到大学，即可为你生成个性化导师，解答一切疑难杂题。

### Company Researcher

> https://github.com/exa-labs/company-researcher

快速了解任何(外国)公司的开源 AI 工具：Company Researcher。

只需输入公司的网站链接，即可帮我们从互联网上全面收集关于该公司的信息，包括组织架构、产品、融资情况以及官方媒体账号等等信息。

抓取的数据主要来自各大平台开放的 API，如 Linkedin、X（Twitter）、Yogithub.com/exa-labs/company-researcheruTube、GitHub、Reddit 等。

最终汇总罗列一个详细面板给我们快速了解该家公司，不过从数据来看，主要面向国外公司。

### AudioNotes

> https://github.com/harry0703/AudioNotes

快速将音视频转结构化笔记的开源工具：。

基于 FunASR 和 Qwen2 构建，可快速提取音视频内容，并利用大模型能力整理成一份结构化的 Markdown 笔记，方便快速阅读。

工具支持搭配 Ollama 使用本地模型，并提供了 Docker 快速部署方式。

### Scira 开源 AI 搜索引擎

> https://github.com/zaidmukaddam/scira

集成 DeepSeek、Claude、Grok 等模型以及各种 API，实现了实时天气查询、代码片段运行、地图导航、学术搜索、视频搜索、X 帖子搜索等等功能。同时，提供简洁好用的可视化界面，并能为我们清晰展示相关搜索到的内容。可以通过 Vercel 快速部署使用。
