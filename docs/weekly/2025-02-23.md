---
title: Mine Weekly 第 62 期
description:
outline: [2, 3]
hidden: true
date: 2025-02-23
recommend: -83
---

## 🚀 科技动态

> 最新的科技进展和市场动态，包括新闻、行业动态、趋势分析

## 💻 技术文章

> 各种技术的应用和实践方法，包括各种技术文章、教程、实践案例等内容

### 推理类模型的最佳实践
> https://platform.openai.com/docs/guides/reasoning-best-practices

OpenAI官方博客发布，指导大家如何更好的使用o1、o3这类推理模型，当然也可以应用在 deepseek r1上。

什么时候使用推理模型？
1. 处理模糊任务
2. 处理大量非结构化信息
3. 在大型数据集中寻找关系和细微差别
4. 多步骤
怎么有效的用推理模型？
1. 保持提示简单直接
2. 避免思维链提示
3. 使用分隔符以提高清晰度：使用分隔符（如 Markdown、XML 标签和章节标题）来清楚地指示输入的不同部分，这有助于模型正确地解释各个部分。
4. 首先尝试零样本，如果需要再尝试少样本：推理模型通常不需要少样本示例就能产生好的结果，所以首先尝试编写没有示例的提示。 如果你对期望的输出有更复杂的要求，在提示中包含一些输入和期望输出的示例可能会有所帮助。但要确保示例与你的提示指令非常一致，因为两者之间的差异可能会导致不良结果。
5. 提供具体的指导方针： 如果你想明确地限制模型的响应（例如“提出一个预算低于 500 美元的解决方案”），请在提示中明确地列出这些约束条件。
6. 非常明确地说明你的最终目标： 在你的指令中，尝试为成功的响应提供非常具体的参数，并鼓励模型持续推理和迭代，直到符合你的成功标准。


### 如何更好的为 DeepSeek R1 或 OpenAI o1 这样的推理模型写提示词？

> https://techcommunity.microsoft.com/blog/azure-ai-services-blog/prompt-engineering-for-openai%E2%80%99s-o1-and-o3-mini-reasoning-models/4374010

1. 保证提示清晰且具体
明确说明你想让模型完成什么。避免不相关的信息。如果问题复杂，可直接简要陈述，不要同时抛出多个话题或做过多背景描述。

2. 必要的上下文要提供，不相关的要省略
包含模型所需的领域信息或数据（如案例、事实），因为模型未必具备最新或小众知识；但别堆砌与任务无关的材料或一堆示例，以免干扰。

3. 尽量零示例或极少示例
优先采用零示例模式。只有当模型理解有误或者格式不对时，才加入简短的示例作为演示。O1/O3 本身不需要像旧版 GPT 那样大量示例来引导。

4. 使用 System/Developer 指令定位角色与风格
比如「你是一位法律分析师」，或「请做一名数学老师给学生讲解」，从而设置合适的专业度和语气；再如「请用条列式列出答案」，指定输出结构。

5. 通过指令控制回答长度与详细程度
若要简短回答，就写「限一段话内给出结论」；若要详细分析，就写「请详述你的推理过程」。O1 默认会倾向详尽，但你可以覆盖该默认。

6. 在 O3-mini 上使用“推理努力程度”参数
（若 API 允许）根据任务需求设置低/中/高，以在速度与准确性之间做平衡。

7. 避免重复的“逐步思考”指示
不必告诉 O1/O3「让我们一步步思考」，因为它们已在内部做链式推理；这类指令对 GPT-4o 更有效。只有当你想要输出“所有中间步骤”时才额外声明。

8. 测试和迭代
如果初始回答不理想，可以改变提示表述或更精确地说明需求。虽然 O1/O3 通常一次就能给出高质量解答，但微调提示仍能进一步提升可读性或输出形式。

9. 对重要结论做验证
对于需要高可靠度的回答，可进行追问或多次查询，并对比不同答案或让模型自检，以增强对结果的信心。即便是 O1 也有可能出错，务必审慎使用。


### 如何构建靠谱的AI agent？

> https://www.anthropic.com/research/building-effective-agents

这是一篇来自于Anthropic Claude团队的座谈交流。他们围绕agents的定义、实践经验与未来展望展开了一个深入对话。

文章从理论到实践全面阐述了AI agent的开发要点：
1. 首先明确区分了agent和工作流的本质区别，agent具有自主决策能力而非简单的固定流程；
2. 在代码实现层面，详细对比了工作流的线性特征和agent的灵活性；同时强调了开发者需要深入理解模型视角，在设计时保持同理心。
3. 在工具设计方面，文章指出了开发者常见的忽视工具接口友好性的误区。
对于agent的应用前景，文章认为目前消费级 agent 被过度炒作，存在偏好表达复杂和风险控制等挑战，而企业级应用则更具潜力，特别适合自动化重复性任务。
最后，专家们建议开发者建立完善的度量体系，并着眼于开发能随模型进步而持续改进的产品。

我印象比较深刻的有三句话：
1. Agents不是工作流，而是管理工作流的自动化流程；
2. 对Agents工作要有同理心，人要站在机器的视角考虑流程是否奏效；
3. 最后一句，是奥特曼也说过很多次的，构建的工具要考虑模型演进，如果你的工具在模型演进之后失去意义了，那么即是坏选择，如果模型越好，你的工具越好，就是好选择。

## 🔧 工具资源

> 如何使用这些工具提高工作效率，包括各种技术工具、软件、插件等方面的内容，各种技术资源、免费课程、学习资料

### DeeSearcher 开源版 Deep Research

> https://github.com/zilliztech/deep-searcher

结合了大模型和向量数据库，为个人/企业知识管理、智能问答、信息搜索等场景提供高度准确的答案和全面分析。

支持本地文件导入，以及网络数据爬取等文档加载，支持 DeepSeek、OpenAI 等大模型。





## 😛 我在看

